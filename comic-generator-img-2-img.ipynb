{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f054479-c470-4ed8-a27b-294b08e8087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation in progress...\n",
      "Installtion complete...\n"
     ]
    }
   ],
   "source": [
    "# Required packages, install if not installed (assume PyTorch* and IntelÂ® Extension for PyTorch* is already present)\n",
    "!echo \"Installation in progress...\"\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install  invisible-watermark > /dev/null\n",
    "# !conda install -y --quiet --prefix {sys.prefix}  -c conda-forge \\\n",
    "#     accelerate==0.23.0 \\\n",
    "#     validators==0.22.0 \\\n",
    "#     diffusers==0.18.2 \\\n",
    "#     transformers==4.32.1 \\\n",
    "#     tensorboardX \\\n",
    "#     pillow \\\n",
    "#     ipywidgets \\\n",
    "#     ipython > /dev/null && echo \"Installation successful\" || echo \"Installation failed\"\n",
    "import sys\n",
    "!{sys.executable} -m pip install invisible-watermark --user > /dev/null 2>&1 \n",
    "!{sys.executable} -m pip install transformers huggingface-hub --user > /dev/null 2>&1\n",
    "!echo \"Installtion complete...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fa73d0-71cd-4990-9924-9289ac987547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "# Suppress warnings for a cleaner output.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import intel_extension_for_pytorch as ipex  # adds xpu namespace to PyTorch, enabling you to use Intel GPUs\n",
    "import validators\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28978aec-c869-464f-a35c-d0f16beb85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img2ImgModel:\n",
    "    \"\"\"\n",
    "    This class creates a model for transforming images based on given prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id_or_path: str,\n",
    "        device: str = \"xpu\",\n",
    "        torch_dtype: torch.dtype = torch.bfloat16,\n",
    "        optimize: bool = True,\n",
    "        warmup: bool = False,\n",
    "        scheduler: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model with the specified parameters.\n",
    "\n",
    "        Args:\n",
    "            model_id_or_path (str): The ID or path of the pre-trained model.\n",
    "            device (str, optional): The device to run the model on. Defaults to \"xpu\".\n",
    "            torch_dtype (torch.dtype, optional): The data type to use for the model. Defaults to torch.float16.\n",
    "            optimize (bool, optional): Whether to optimize the model. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.data_type = torch_dtype\n",
    "        self.scheduler = scheduler\n",
    "        self.generator = torch.Generator()  # .manual_seed(99)\n",
    "        self.pipeline = self._load_pipeline(model_id_or_path, torch_dtype)\n",
    "        if optimize:\n",
    "            start_time = time.time()\n",
    "            #print(\"Optimizing the model...\")\n",
    "            self.optimize_pipeline()\n",
    "            #print(\n",
    "            #    \"Optimization completed in {:.2f} seconds.\".format(\n",
    "            #        time.time() - start_time\n",
    "            #    )\n",
    "            #)\n",
    "        if warmup:\n",
    "            self.warmup_model()\n",
    "\n",
    "    def _load_pipeline(\n",
    "        self, model_id_or_path: str, torch_dtype: torch.dtype\n",
    "    ) -> StableDiffusionImg2ImgPipeline:\n",
    "        \"\"\"\n",
    "        Load the pipeline for the model.\n",
    "\n",
    "        Args:\n",
    "            model_id_or_path (str): The ID or path of the pre-trained model.\n",
    "            torch_dtype (torch.dtype): The data type to use for the model.\n",
    "\n",
    "        Returns:\n",
    "            StableDiffusionImg2ImgPipeline: The loaded pipeline.\n",
    "        \"\"\"\n",
    "        print(\"Loading the model...\")\n",
    "        model_path = Path(f\"/home/common/data/Big_Data/GenAI/{model_id_or_path}\")\n",
    "        \n",
    "        if model_path.exists():\n",
    "            #print(f\"Loading the model from {model_path}...\")\n",
    "            load_path = model_path\n",
    "        else:\n",
    "            print(\"Using the default path for models...\")\n",
    "            load_path = model_id_or_path\n",
    "            \n",
    "        pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "            load_path,\n",
    "            torch_dtype=torch_dtype,\n",
    "            use_safetensors=True,\n",
    "            variant=\"fp16\",\n",
    "        )\n",
    "        if self.scheduler:\n",
    "            pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "                pipeline.scheduler.config\n",
    "            )\n",
    "        if not model_path.exists():\n",
    "            try:\n",
    "                print(f\"Attempting to save the model to {model_path}...\")\n",
    "                pipeline.save_pretrained(f\"{model_path}\")\n",
    "                print(\"Model saved.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the model: {e}. Proceeding without saving.\")\n",
    "        pipeline = pipeline.to(self.device)\n",
    "        #print(\"Model loaded.\")\n",
    "        return pipeline\n",
    "\n",
    "    def _optimize_pipeline(\n",
    "        self, pipeline: StableDiffusionImg2ImgPipeline\n",
    "    ) -> StableDiffusionImg2ImgPipeline:\n",
    "        \"\"\"\n",
    "        Optimize the pipeline of the model.\n",
    "\n",
    "        Args:\n",
    "            pipeline (StableDiffusionImg2ImgPipeline): The pipeline to optimize.\n",
    "\n",
    "        Returns:\n",
    "            StableDiffusionImg2ImgPipeline: The optimized pipeline.\n",
    "        \"\"\"\n",
    "        for attr in dir(pipeline):\n",
    "            if isinstance(getattr(pipeline, attr), nn.Module):\n",
    "                setattr(\n",
    "                    pipeline,\n",
    "                    attr,\n",
    "                    ipex.optimize(\n",
    "                        getattr(pipeline, attr).eval(),\n",
    "                        dtype=pipeline.text_encoder.dtype,\n",
    "                        inplace=True,\n",
    "                    ),\n",
    "                )\n",
    "        return pipeline\n",
    "\n",
    "    def optimize_pipeline(self) -> None:\n",
    "        \"\"\"\n",
    "        Optimize the pipeline of the model.\n",
    "        \"\"\"\n",
    "        self.pipeline = self._optimize_pipeline(self.pipeline)\n",
    "\n",
    "    def get_image_from_url(self, url: str, path: str) -> Image.Image:\n",
    "        \"\"\"\n",
    "        Get an image from a URL or from a local path if it exists.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the image.\n",
    "            path (str): The local path of the image.\n",
    "\n",
    "        Returns:\n",
    "            Image.Image: The loaded image.\n",
    "        \"\"\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                f\"Failed to download image. Status code: {response.status_code}\"\n",
    "            )\n",
    "        if not response.headers[\"content-type\"].startswith(\"image\"):\n",
    "            raise Exception(\n",
    "                f\"URL does not point to an image. Content type: {response.headers['content-type']}\"\n",
    "            )\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img.save(path)\n",
    "        img = img.resize((768, 512))\n",
    "        return img\n",
    "\n",
    "    def warmup_model(self):\n",
    "        \"\"\"\n",
    "        Warms up the model by generating a sample image.\n",
    "        \"\"\"\n",
    "        print(\"Setting up model...\")\n",
    "        start_time = time.time()\n",
    "        image_url = \"https://user-images.githubusercontent.com/786476/256401499-f010e3f8-6f8d-4e9f-9d1f-178d3571e7b9.png\"\n",
    "        try:\n",
    "            self.generate_images(\n",
    "                image_url=image_url,\n",
    "                prompt=\"A beautiful day\",\n",
    "                num_images=1,\n",
    "                save_path=\".tmp\",\n",
    "            )\n",
    "        except Exception:\n",
    "            print(\"model warmup delayed...\")\n",
    "        #print(\n",
    "        #    \"Model is set up and ready! Warm-up completed in {:.2f} seconds.\".format(\n",
    "        #        time.time() - start_time\n",
    "        #    )\n",
    "        #)\n",
    "\n",
    "    def get_inputs(self, prompt, batch_size=1):\n",
    "        self.generator = [torch.Generator() for i in range(batch_size)]\n",
    "        prompts = batch_size * [prompt]\n",
    "        return {\"prompt\": prompts, \"generator\": self.generator}\n",
    "\n",
    "    def generate_images(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        image_url: str,\n",
    "        num_images: int = 5,\n",
    "        num_inference_steps: int = 30,\n",
    "        strength: float = 0.75,\n",
    "        guidance_scale: float = 7.5,\n",
    "        save_path: str = \"image_to_image\",\n",
    "        batch_size: int = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate images based on the provided prompt and variations.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The base prompt for the generation.\n",
    "            image_url (str): The URL of the seed image.\n",
    "            variations (List[str]): The list of variations to apply to the prompt.\n",
    "            num_images (int, optional): The number of images to generate. Defaults to 5.\n",
    "            num_inference_steps (int, optional): Number of noise removal steps.\n",
    "            strength (float, optional): The strength of the transformation. Defaults to 0.75.\n",
    "            guidance_scale (float, optional): The scale of the guidance. Defaults to 7.5.\n",
    "            save_path (str, optional): The path to save the generated images. Defaults to \"image_to_image\".\n",
    "\n",
    "        \"\"\"\n",
    "        input_image_path = \"input.png\"\n",
    "        if validators.url(image_url):\n",
    "            init_image = self.get_image_from_url(image_url, input_image_path)\n",
    "        elif os.path.isfile(image_url):\n",
    "            init_image = Image.open(image_url).convert(\"RGB\")\n",
    "        else:\n",
    "            raise ValueError(\"The image_input is neither a valid URL nor a local file path.\")\n",
    "        init_images = [init_image for _ in range(batch_size)]\n",
    "\n",
    "        generated_image_paths = []\n",
    "\n",
    "        for i in range(0, num_images, batch_size):\n",
    "            with torch.xpu.amp.autocast(\n",
    "                enabled=True if self.data_type != torch.float32 else False,\n",
    "                dtype=self.data_type,\n",
    "            ):\n",
    "                if batch_size > 1:\n",
    "                    inputs = self.get_inputs(batch_size=batch_size, prompt=prompt)\n",
    "                    images = self.pipeline(\n",
    "                        **inputs,\n",
    "                        image=init_images,\n",
    "                        strength=strength,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                        num_inference_steps=num_inference_steps,\n",
    "                    ).images\n",
    "                else:\n",
    "                    images = self.pipeline(\n",
    "                        prompt=prompt,\n",
    "                        image=init_images,\n",
    "                        strength=strength,\n",
    "                        guidance_scale=guidance_scale,\n",
    "                        num_inference_steps=num_inference_steps,\n",
    "                    ).images\n",
    "\n",
    "                for j in range(len(images)):\n",
    "                    output_image_path = os.path.join(\n",
    "                        save_path,\n",
    "                        f\"{'_'.join(prompt.split()[:3])}_{i+j}__{int(time.time() * 1e6)}.png\",\n",
    "                    )\n",
    "                    images[j].save(output_image_path)\n",
    "                    generated_image_paths.append(output_image_path)\n",
    "                    \n",
    "                return generated_image_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd38307-334d-4bef-af01-fd493c60b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "class ComicGenerationModel:\n",
    "    \"\"\"\n",
    "    ComicGenerationModel generates a series of images that tell a story based on an initial text prompt and a reference image.\n",
    "    It combines text-to-image and image-to-image transformation capabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text_model_id, img_model_id, device='xpu', torch_dtype=torch.bfloat16, optimize=True, warmup=True):\n",
    "        \"\"\"\n",
    "        Initialize both Text2ImgModel and Img2ImgModel within the comic generation model.\n",
    "\n",
    "        Args:\n",
    "            text_model_id (str): Identifier for the text-to-image model.\n",
    "            img_model_id (str): Identifier for the image-to-image model.\n",
    "            device (str, optional): Device to run the models on. Defaults to 'xpu'.\n",
    "            torch_dtype (torch.dtype, optional): Data type for the models. Defaults to torch.bfloat16.\n",
    "            optimize (bool, optional): Whether to optimize models on initialization. Defaults to True.\n",
    "            warmup (bool, optional): Whether to warm up models on initialization. Defaults to True.\n",
    "        \"\"\"\n",
    "        #self.text_to_img_model = Text2ImgModel(text_model_id, device, torch_dtype, optimize, warmup)\n",
    "        self.img_to_img_model = Img2ImgModel(img_model_id, device, torch_dtype, optimize, warmup)\n",
    "\n",
    "    def get_image_from_url(self, url: str) -> Image.Image:\n",
    "        \"\"\"\n",
    "        Download an image from a URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): URL of the image to download.\n",
    "\n",
    "        Returns:\n",
    "            Image.Image: The downloaded image.\n",
    "        \"\"\"\n",
    "        #print(f'getting image for {url}')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "        if not response.headers[\"content-type\"].startswith(\"image\"):\n",
    "            raise Exception(f\"URL does not point to an image. Content type: {response.headers['content-type']}\")\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        return img\n",
    "\n",
    "    def generate_comic(self, initial_prompt, reference_image_url, story_prompts, save_path=\"comic_output\"):\n",
    "        \"\"\"\n",
    "        Generate a comic story based on an initial prompt and a series of evolving story prompts.\n",
    "\n",
    "        Args:\n",
    "            initial_prompt (str): The initial text prompt for the first image.\n",
    "            reference_image_url (str): URL of the reference image for the first image.\n",
    "            story_prompts (list of str): A list of text prompts for subsequent images in the story.\n",
    "            save_path (str, optional): Directory to save the generated comic images. Defaults to \"comic_output\".\n",
    "        \"\"\"\n",
    "        if not isinstance(story_prompts, list) or len(story_prompts) != 4:\n",
    "            raise ValueError(\"story_prompts must be a list of four strings\")\n",
    "\n",
    "        # Generate the first image from text and reference image\n",
    "        #print('we are here')\n",
    "        reference_image = self.get_image_from_url(reference_image_url)\n",
    "        #first_image = self.text_to_img_model.generate_images(initial_prompt, num_images=1, save_path=save_path)[0]\n",
    "        #print(f'calling generate_images with {initial_prompt},\\n {reference_image_url}, \\n{save_path} \\n')\n",
    "        first_image_list = self.img_to_img_model.generate_images(\n",
    "            prompt=initial_prompt,\n",
    "            image_url= reference_image_url, #reference_image,  # Use the downloaded image\n",
    "            num_images=1,\n",
    "            save_path=save_path\n",
    "        )\n",
    "        if not first_image_list:\n",
    "            raise Exception(\"No images were generated.\")\n",
    "        \n",
    "        first_image = first_image_list[0]\n",
    "        #print(f'generated first image!\\n')\n",
    "\n",
    "        # Generate subsequent images based on previous image and new prompts\n",
    "        previous_image = first_image\n",
    "        for i, prompt in enumerate(story_prompts, start=1):\n",
    "            #print(f'going for {i} prompt with {prompt}')\n",
    "            subsequent_image = self.img_to_img_model.generate_images(prompt, previous_image, num_images=1, save_path=save_path)[0]\n",
    "            previous_image = subsequent_image\n",
    "\n",
    "        print(f\"Comic story generated in {save_path}\")\n",
    "\n",
    "# Usage Example\n",
    "# comic_gen = ComicGenerationModel('text_model_id_here', 'img_model_id_here')\n",
    "# initial_prompt = \"A wizard in a mystical forest\"\n",
    "# reference_image_url = \"https://example.com/wizard_reference.jpg\"\n",
    "# story_prompts = [\"The wizard encounters a talking tree\", \"A magical battle begins\", \"Victory and discovery of a hidden treasure\", \"The wizard's return to the village\"]\n",
    "# comic_gen.generate_comic(initial_prompt, reference_image_url, story_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffa340c9-632b-42d5-8dbe-7dfcfcabf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mp_img\n",
    "import validators\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "model_cache = {}\n",
    "\n",
    "def generate_comic_gui():\n",
    "    out = widgets.Output()\n",
    "    output_dir = \"comic_output\"\n",
    "    model_ids = [\n",
    "        \"stabilityai/stable-diffusion-2-1\",  \n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        \"stabilityai/sdxl-turbo\",\n",
    "    ]    \n",
    "    \n",
    "    model_dropdown = widgets.Dropdown(\n",
    "        options=model_ids,\n",
    "        value=model_ids[0],\n",
    "        description=\"Model:\",\n",
    "    )    \n",
    "    initial_prompt_text = widgets.Text(\n",
    "        value=\"\",\n",
    "        placeholder=\"Enter the initial prompt\",\n",
    "        description=\"Initial Prompt:\",\n",
    "        layout=widgets.Layout(width=\"600px\")\n",
    "    )    \n",
    "    reference_image_url_text = widgets.Text(\n",
    "        value=\"\",\n",
    "        placeholder=\"Enter the reference image URL\",\n",
    "        description=\"Image URL:\",\n",
    "        layout=widgets.Layout(width=\"600px\")\n",
    "    )    \n",
    "    story_prompts_textarea = widgets.Textarea(\n",
    "        value=\"\",\n",
    "        placeholder=\"Enter story prompts separated by line breaks\",\n",
    "        description=\"Story Prompts:\",\n",
    "        layout=widgets.Layout(width=\"600px\", height=\"100px\")\n",
    "    )    \n",
    "\n",
    "    layout = widgets.Layout(margin=\"20px\")\n",
    "    button = widgets.Button(description=\"Generate Comic!\", button_style=\"primary\")   \n",
    "    model_dropdown.layout.width = \"70%\"\n",
    "    initial_prompt_text.layout.width = \"100%\"\n",
    "    reference_image_url_text.layout.width = \"100%\"\n",
    "    story_prompts_textarea.layout.width = \"100%\"\n",
    "    button.layout.margin=\"0 0 0 400px\"\n",
    "    top_row = widgets.HBox([model_dropdown])\n",
    "    middle_row = widgets.HBox([initial_prompt_text])\n",
    "    middle_row_2 = widgets.HBox([reference_image_url_text])\n",
    "    bottom_row = widgets.HBox([story_prompts_textarea])\n",
    "    left_box = widgets.VBox([top_row, middle_row, middle_row_2, bottom_row])\n",
    "    user_input_widgets = widgets.HBox([left_box], layout=layout)\n",
    "    display(user_input_widgets)\n",
    "    display(button)\n",
    "    display(out)\n",
    "\n",
    "    def on_submit(button):\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "            button.button_style = \"warning\"\n",
    "            print(\"\\nOnce generated, comic will be saved to `./comic_output` dir, please wait...\")\n",
    "            selected_model_index = model_ids.index(model_dropdown.value)\n",
    "            model_id = model_ids[selected_model_index]\n",
    "            model_key = (model_id, \"xpu\")\n",
    "            if model_key not in model_cache:\n",
    "                #print('model not in model_cache')\n",
    "                model_cache[model_key] = ComicGenerationModel(text_model_id=model_ids[0], img_model_id=model_ids[1], device=\"xpu\")\n",
    "            initial_prompt = initial_prompt_text.value\n",
    "            reference_image_url = reference_image_url_text.value\n",
    "            if not validators.url(reference_image_url):\n",
    "                print(f'Invalid reference image URL: {reference_image_url}')\n",
    "                return\n",
    "            story_prompts = story_prompts_textarea.value.split('\\n')\n",
    "            model = model_cache[model_key]\n",
    "\n",
    "            if not initial_prompt or not reference_image_url or len(story_prompts) != 4:\n",
    "                print(\"Please provide a valid initial prompt, reference image URL, and exactly four story prompts.\")\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                #print('start generate_comic')\n",
    "                model.generate_comic(\n",
    "                    initial_prompt,\n",
    "                    reference_image_url,\n",
    "                    story_prompts,\n",
    "                    save_path=\"./comic_output\",\n",
    "                )\n",
    "                clear_output(wait=True)\n",
    "                display_generated_images(output_dir=output_dir)\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nUser interrupted comic generation...\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "            finally:\n",
    "                button.button_style = \"primary\"\n",
    "                \n",
    "    button.on_click(on_submit)\n",
    "\n",
    "def display_generated_images(output_dir=\"comic_output\"):\n",
    "    image_files = [f for f in os.listdir(output_dir) if f.endswith((\".png\", \".jpg\"))]    \n",
    "    num_images = len(image_files)\n",
    "    num_columns = int(np.ceil(np.sqrt(num_images)))\n",
    "    num_rows = int(np.ceil(num_images / num_columns))\n",
    "    fig, axs = plt.subplots(num_rows, num_columns, figsize=(10 * num_columns / num_columns, 10 * num_rows / num_rows))\n",
    "    if num_images == 1:\n",
    "        axs = np.array([[axs]])\n",
    "    elif num_columns == 1 or num_rows == 1:\n",
    "        axs = np.array([axs])\n",
    "    for ax, image_file in zip(axs.ravel(), image_files):\n",
    "        img = mp_img.imread(os.path.join(output_dir, image_file))\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")  # Hide axes\n",
    "    for ax in axs.ravel()[num_images:]:\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    print(f\"\\nGenerated images...:\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad028270-3a43-4d8e-be8a-6ef983827ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6193247e7743188c65d1897835f8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(Dropdown(description='Model:', layout=Layout(width='70%'), optionâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe18ce5ac214440bbc28f60d67c66114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Generate Comic!', layout=Layout(margin='0 0 0 400px'), style=Buttoâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9419a7d4f04ae083a12613332a691e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run all cells before running this section and wait a few seconds for UI to load\n",
    "generate_comic_gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9659156-24a3-4547-bbc3-f30266de255b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
